{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f020c-153b-40cb-ac34-46ac3680cce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install openai anthropic IPython\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display\n",
    "import time\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "# deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff397b-5feb-42e3-8f0f-1589026b3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking keys\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "# if anthropic_api_key:\n",
    "#     print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "# else:\n",
    "#     print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "# if deepseek_api_key:\n",
    "#     print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "# else:\n",
    "#     print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d5c02-a33c-4aca-8e83-7b3ea2a13974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Question!\n",
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Make output in markdown format design\"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]\n",
    "\n",
    "# Setup question and display with markdown + timer\n",
    "openai = OpenAI()\n",
    "\n",
    "q_start_time = time.time() \n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "q_end_time = time.time()\n",
    "duration = q_end_time - q_start_time\n",
    "display(Markdown(question))\n",
    "print(f\"\\nTime taken for API call for question: **{duration:.4f} seconds**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c6cf5-8593-4fc4-907a-cd5a697f2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for the competition!\n",
    "\n",
    "competitors = []\n",
    "answers = []\n",
    "durations = []\n",
    "question += \"Don't make too long answer and arrange the output in Markdown format. No continuation of the chat, stop after the answer.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daefe1b4-0d6a-420a-92a1-14ffe2938ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Competitor1\n",
    "\n",
    "model_name = \"gpt-5-mini\"\n",
    "\n",
    "c1_start_time = time.time()\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "c1_end_time = time.time()\n",
    "c1_duration = c1_end_time - c1_start_time\n",
    "\n",
    "print(f\"\\nTime taken for {model_name} API call: **{c1_duration:.4f} seconds**\")\n",
    "display(Markdown(answer))\n",
    "\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n",
    "durations.append(c1_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4dd68-cfd8-4aed-85cf-8c7e982f19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "# model_name = \"claude-sonnet-4-5\"\n",
    "\n",
    "# claude = Anthropic()\n",
    "# response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "# answer = response.content[0].text\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)\n",
    "\n",
    "\n",
    "# Deepseek\n",
    "# deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "# model_name = \"deepseek-chat\"\n",
    "\n",
    "# response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.choices[0].message.content\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841702dc-a678-4240-9cf8-fdea2112c14f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Competitor 2\n",
    "\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "c2_start_time = time.time()\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "c2_end_time = time.time()\n",
    "c2_duration = c2_end_time - c2_start_time\n",
    "\n",
    "print(f\"Time taken for {model_name}: **{c2_duration:.4f} seconds**\\n\")\n",
    "display(Markdown(answer))\n",
    "\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n",
    "durations.append(c2_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e93fd-fdf9-49d1-a476-17a741b6542f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Competitor 3\n",
    "\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"openai/gpt-oss-120b\"\n",
    "\n",
    "c3_start_time = time.time()\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "c3_end_time = time.time()\n",
    "c3_duration = c3_end_time - c3_start_time\n",
    "\n",
    "print(f\"Time taken for {model_name}: **{c3_duration:.4f} seconds**\\n\")\n",
    "display(Markdown(answer))\n",
    "\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n",
    "durations.append(c3_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e174630-f3b5-426c-8f75-47c72fab8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(competitors)\n",
    "print(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b2c02-4f26-4bd4-9050-7d005e11a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "competitors_answers = pd.DataFrame({\n",
    "    \"Model\": competitors,\n",
    "    \"Answer\": answers,\n",
    "    \"Time (s)\": [round(d, 3) for d in durations]\n",
    "})\n",
    "\n",
    "competitors_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac17ea-ed6e-42e2-b1b2-50ef45226b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FINAL JUDGING STATE\n",
    "# Combine all answers nicely\n",
    "together = \"\\n\\n\".join(\n",
    "\tf\"### Competitor {i + 1}: **{competitors[i]}**\\n{answer}\"\n",
    "\tfor i, answer in enumerate(answers)\n",
    ")\n",
    "\n",
    "display(Markdown(together))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4ce72d-464b-4be1-9fcb-7b595b228c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — JUDGE PROMPT —\n",
    "start_time = time.time()\n",
    "\n",
    "judge_prompt = f\"\"\"Question asked:\n",
    "{question.strip()}\n",
    "\n",
    "Evaluate these {len(competitors)} responses for accuracy, clarity, reasoning, and overall quality.\n",
    "\n",
    "Responses:\n",
    "{together}\n",
    "\n",
    "Return a clean Markdown response with:\n",
    "1. Ranked list from best to worst\n",
    "2. Short 1-sentence explanation for the winner\n",
    "3. Final winner announcement\n",
    "\n",
    "Use this exact format:\n",
    "## Ranking\n",
    "1. ...\n",
    "2. ...\n",
    "\n",
    "## Winner Explanation\n",
    "...\n",
    "\n",
    "## Final Winner\n",
    "**Winner: ...**\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "\tmodel=\"gpt-5\",\n",
    "\tmessages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
    ")\n",
    "\n",
    "judgement = response.choices[0].message.content\n",
    "judge_duration = time.time() - start_time\n",
    "\n",
    "# ── DISPLAY RESULT ──\n",
    "display(Markdown(\"# LLM Competition Judgement\"))\n",
    "display(Markdown(f\"**Judging time: {judge_duration:.2f} seconds**\"))\n",
    "display(Markdown(judgement))\n",
    "\n",
    "# ── SAVE TO FILE WITH DURATION ──\n",
    "with open(\"final_judgement.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "\tf.write(f\"# LLM Competition Judgement\\n\\n\")\n",
    "\tf.write(f\"**Judged in {judge_duration:.2f} seconds**\\n\\n\")\n",
    "\tf.write(judgement)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
